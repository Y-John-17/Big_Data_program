# 分布式计算框架 MapReduce

## 一、本质定性

### 1.1 定义

MapReduce是一种架构在大型商用集群中对海量数据集的容错性高、可靠处理的分布式计算框架。

### 1.2 原理

将问题（或是要处理的数据集）进行聚类分割处理，最后对结果进行合并，得到最终的问题解决方案。

### 1.3 优缺点

优：更合适大文件、海量流式数据的处理；

缺：对于小文件的处理效率并不是很高

## 二、编程模型简介

### 2.1  模型介绍

MapReduce模型是一种分布式计算框架，架构在hadoop内，由两个抽象类构成，两者只接受键值类型数据；Mapper用于对原数据的预处理、分割，Reducer对数据做处理后，对数据结果进行汇总，得到输出结果。

![Mapreducer基本原理图](D:\桌面数据\Mapreducer基本原理图.png)

### 2.2  编程模型分类

（1）简单模型

数据集只需简单处理，例如数据集文本格式转换，数据简单分类（占少数情况）

（2）复杂模型

通过Mapper预处理，数据分块传输到Reducer（默认启动一个，用户可动态调节），分布计算合并结果并返回

### 2.3   需要注意的点

（1）Reducer类的处理模块的数量可根据Mapper的数据集分割量用户动态调节。

（2）数据处理返回（键值）通常以升序排序方式。

（3）Mapper类问题的分割方式并无统一标准，需要动态调节

（4）使用于大问题分解而成的小问题彼此之间没有依赖关系存在

## 三、MapReduce数据流

### 3.1  简介

在Mapper和Reducer整个处理过程中数据传递都是以键值对类型传输，数据源来自hadoop提供的基本API而实现，用户再次基础上可按需求进行继承覆盖实现特殊操作

### 3.2  数据流处理过程

#### 3.2.1  分片、格式化数据源（InputFormat）

主要功能

（1）源文件（海量大数据）分片处理，确定Mapper数量（分类聚心数量）

（2）源文件格式化处理，处理成<key,value>键值对形式数据传输给Mapper

#### 3.2.2  Map过程

接收键值对类型数据，返回键值对类型数据，具体过程可用户定义

#### 3.2.3  Combiner过程

对Map向Reducer传输前做一次合并，减少数据传输、提高网络I/O性能，优化工作流程

#### 3.2.4  Shuffle过程

不直接写入磁盘操作，存储在内存中达到一定阈值写入磁盘，并同时进行sort（排序）对来自Mapper按key值排序、combine（合并）把key相同的相邻记录合并、partition（分片）将数据均匀分配给多个Reducer

注：Mapper数量总是多于Reducer，Reducer常常从其他多个结点下载Mapper数据结果，Reducer的处理效率离不开Mapper上一步数据处理的结果运用。

#### 3.2.5  Reducer过程

输入输出均以键值对形式，输出数据直接写入HDFS，具体处理过程可由用户定义。

## 四、MapReduce任务运行流程

### 4.1  Mrv2基本组成

舍弃了Jobtrack和TaskTrack，采用MARAppMaster进行单一任务管理，与Yarn中ResouceManage和Node Manager协同调度与控制，避免了第一调度而产生的负载问题

4.1.1  客户端

用于向yarn集群提交任务，实现Map Reduce用户和Yarn集群通信的唯一突进直接监视和控制作业，减轻ResouceManager负担

4. 1.2  MRAppMaster

监视和调度一整套MR任务流程，每个MR只产生一个MRAppMaster,负责任务管理，不负责资源调配

4. 1.3  Map task 和Reduce task

用户定义的Map函数和Reduce函数的实例比，运行在Yarn给定的资源限制下，由MRAppMaster和NodeManager协同管理

## 4.2  Yarn基本组成

4.2.1 简介

资源管理平台，监视和调度整个集群资源，并负责所有集群任务分配

4.2.2  任务流程

资源管理由ResouceManage和Node Manager共同完成，ResouceManage负责资源分配，Node Manager负责资源供给和隔离